# Monte Carlo Security Questionnaire Skill


## Purpose
Quick reference facts from approved public sources for completing security questionnaires about Monte Carlo Data, Inc.


**CRITICAL**: Contains ONLY verified information from Monte Carlo's official public documentation. Never add inferred information.


## Approved Documentation Sources
1. https://docs.getmontecarlo.com/docs/access-management
2. https://docs.getmontecarlo.com/docs/data-protection-and-encryption
3. https://docs.getmontecarlo.com/docs/infrastructure-security
4. https://docs.getmontecarlo.com/docs/application-security
5. https://docs.getmontecarlo.com/docs/ai-security
6. https://docs.getmontecarlo.com/docs/llm-training-observability
7. https://docs.getmontecarlo.com/docs/vulnerability-disclosure-policy
8. https://docs.getmontecarlo.com/docs/compliance
9. https://docs.getmontecarlo.com/docs/privacy
10. https://docs.getmontecarlo.com/docs/subprocessors-vendors
11. https://docs.getmontecarlo.com/docs/info-monte-carlo-collects
12. https://docs.getmontecarlo.com/docs/data-sampling
13. https://docs.getmontecarlo.com/docs/hosting-architecture-options
14. https://docs.getmontecarlo.com/docs/regional-hosting
15. https://docs.getmontecarlo.com/docs/dedicated-instance
16. https://docs.getmontecarlo.com/docs/ai-features-and-technical-info


---


## Quick Reference Facts


### Compliance & Certifications
**Source**: /docs/compliance
- SOC 2 Type 2 (annual audits)
- ISO 27001, ISO 27017, ISO 27018
- GDPR and CCPA compliance
- Trust Center: https://trust.montecarlodata.com
- New documentation available by end of July each year
- Customers can subscribe for updates


### Cloud Infrastructure
**Source**: /docs/infrastructure-security, /docs/hosting-architecture-options
- **Provider**: Amazon Web Services (AWS) exclusively
- **Architecture**: AWS Well-Architected and CIS Benchmark guidelines
- **Compute**: AWS Lambda (isolated, short-lived containers with scoped IAM)
- **No Persistent Servers**: Temporary and immutable compute environments
- **Networking**: AWS API Gateway with encryption, rate limits, throttling
- **Segmentation**: Separate production, staging, development environments
- **Protection**: Private VPC endpoints, AWS WAF
- **Regions**: US and EU available
- **Deployment Options**: Regional (multi-tenant) or Dedicated Instance
- **Shared Responsibility**: AWS Shared Responsibility Model


### Encryption & Data Protection
**Source**: /docs/data-protection-and-encryption
- **At Rest**: AES-256
- **In Transit**: TLS 1.2+ with strong cipher suites
- **Key Management**: Secure, audited systems; periodic rotation on schedule
- **Key Access**: Restricted to authorized personnel, logged and monitored
- **Backups**: Encrypted using same standards
- **Company Devices**: Full-disk encryption, strong passwords, screen lock, remote wipe enforced via device management
- **Customer-Managed Keys**: Supported in dedicated/hybrid deployments, self-hosted credentials option
- **Secure Transfer**: SFTP or HTTPS/TLS for data exchanges with third parties


### Access Management
**Source**: /docs/access-management


**Product Access**:
- SSO: SAML 2.0, Okta, Azure AD, other providers
- RBAC: Role-based access control
- SCIM: Automated provisioning/deprovisioning
- Least-privilege configurations
- Audit logs: User logins, configuration changes, admin actions
- Time-bound access supported
- Permissions scoping: By data source, workspace, or domain


**Internal Access**:
- Least-privilege model
- Centralized identity and role-based access
- MFA required for all privileged systems
- Quarterly access reviews
- Privileged sessions monitored, logged, reviewed
- VPN required for production system access
- Termination: Access revoked within 24 hours


**Vendor Access**:
- Only approved subprocessors with due diligence reviews
- Contractual data protection and confidentiality required
- No account-level access except specific engagements (e.g., penetration testing)
- Access documented and approved before provisioning


### Application Security
**Source**: /docs/application-security


**Development Lifecycle**:
- Static and dynamic analysis in CI/CD pipelines
- Dependencies automatically scanned for vulnerabilities
- Peer review and approval required for all changes
- OWASP Top 10 and CWE testing before deployment
- Isolated environments (development, staging, production)
- Formal change-management approvals


**Security Controls**:
- RBAC, SSO, MFA enforced
- Session management limits token lifetimes
- Encryption: TLS 1.2+ (transit), AES-256 (at rest)
- Logical data segregation per customer
- Ongoing vulnerability assessments
- Third-party penetration tests
- Responsible disclosure program
- Findings triaged by severity, tracked through SLAs


**Deployment**:
- Infrastructure-as-Code for approved configurations
- Immutable build artifacts
- Automated rollback
- Separation of duties (engineering vs operations)


**Monitoring**:
- Centralized logging and anomaly detection
- Real-time alerts for suspicious activity
- Integrated with infrastructure defense


### Infrastructure Security
**Source**: /docs/infrastructure-security


**Hardening & Patch Management**:
- Automated scanning and configuration validation
- Infrastructure-as-Code reviews
- Critical issues prioritized, tracked to remediation
- Independent penetration tests (annual)
- Third-party security assessments


**Monitoring**:
- Security telemetry collected and correlated
- SIEM integration
- Immutable logs for audit and forensics
- 24/7 on-call security and engineering teams
- Established incident response procedures


### Data Collection & Monitoring
**Source**: /docs/info-monte-carlo-collects


Monte Carlo collects and processes the following data types for observability:


**1. Metadata** (stored in cloud service):
- Information about tables, schemas, data freshness/volume
- Names and attributes of BI reports/dashboards
- Other attributes of customer data assets
- Collection method: APIs, JDBC connections from customer warehouses, lakes, BI tools
- Purpose: Build catalog of warehouse, lake, BI objects with schema information for observability reports


**2. Metrics** (stored in cloud service):
- Row counts, byte counts, last modification dates
- Table-level metrics
- Collection method: APIs, JDBC connections
- Purpose: Track freshness, volume, data health and distribution


**3. Query Logs** (stored in cloud service):
- History of queries and metadata (timestamp, user, errors)
- Collection method: APIs, JDBC connections
- Purpose: Track lineage, usage analytics, query history for troubleshooting and prevention


**4. Aggregated Statistics** (stored in cloud service):
- Null rates, distinct values, row counts, percentiles
- Statistical measures of data in selected tables
- Collection method: APIs, JDBC connections
- Purpose: Track data health and corruption using ML-based anomaly detection and customer-provided rules


**5. Application Data** (stored in cloud service):
- Customer accounts, user settings, configurations, IP addresses, incidents
- Purpose: User authentication and service setup


**6. Unstructured Data** (stored in cloud service):
- Metadata and statistical data about free-text, images, emails, logs
- Purpose: Monitor sentiment, classification, data consistency; detect drift, hallucination, inconsistency in AI


**7. Data Sampling** (stored in data store):
- Individual values or data records in clear text form
- Associated with data reliability incidents detected by Monte Carlo
- Collection: Sample set from customer tenant
- Purpose: Help users quickly identify nature of data issues and root cause
- **Storage**: Can be in Monte Carlo environment OR customer environment (Hybrid Deployment)
- See: /docs/data-sampling for details


**Key Points**:
- Types 1-6 are non-row level data (metadata, metrics, aggregated stats)
- Type 7 is row-level data, handled differently with flexible storage options
- Customers encouraged to mask/anonymize personal data at source before ingestion
- **PII or Sensitive Data Processing**: Monte Carlo may process and store PII if data sampling is enabled and the row-level (or raw) data contains PII. However:
  - Monte Carlo does not know whether PII is present (customers control what data is monitored)
  - Monte Carlo does not require PII
  - PII is only processed if data sampling is turned on AND customer configures monitoring on data where the row-level data contains PII
  - Monte Carlo recommends data masking/anonymization at source to prevent PII ingestion
  - Same principle applies to other sensitive data types (PHI, financial data, etc.)


### Deployment Models
**Source**: /docs/hosting-architecture-options


**Regional Hosting** (Multi-Tenant):
- Shared infrastructure within defined geographic region
- Logical data and access isolation between tenants
- US and EU regions available


**Hybrid Deployment**:
- Raw data stored in customer environment
- Processed in Monte Carlo environment for short periods as needed


**Dedicated Instance** (Public Preview):
- Physically and logically isolated where possible
- Dedicated resources (compute, database, networking)
- Greater control over configuration, networking, access


### Subprocessors
**Source**: /docs/subprocessors-vendors
- Third-party data processors with potential access to customer data
- Personal data may be processed via data sampling
- Only subset process personal data directly (row-level data/sampling)
- Full list available in documentation
- Subscribe for updates: https://trust.montecarlodata.com
- Contact: [email protected]


---


## TEMPORARY SECTIONS (Pending Public Documentation)


**NOTE**: The following sections are sourced from SOC 2 Type 2 Report and will be replaced with approved public documentation URLs once published.


### Business Continuity & Disaster Recovery
**Source**: SOC 2 BC-01, BC-02, BC-03 (TO BE REPLACED WITH PUBLIC DOCS)


- **BC/DR Plan**: Documented, tested, and approved annually
- **Multi-AZ Replication**: Critical system components replicated across multiple availability zones or regions
- **Backups**: Daily backups of critical system components
- **Testing**: BC/DR plan tested at least annually
- **Recovery**: Defined procedures for resumption of critical operations


### Incident Response
**Source**: SOC 2 IS-07, OM-01, OM-02, OM-05 (TO BE REPLACED WITH PUBLIC DOCS)


**Framework**:
- Documented Incident Response Policy (IRP) reviewed and approved annually
- IRP tested annually (actual incident or tabletop exercise)
- Lifecycle: Preparation, detection, analysis, triage, containment, eradication, recovery, post-mortem


**Severity Levels & SLAs**:
- **SEV-1 (Critical)**: Data breach - Goal Mitigation SLA: 7 days
- **SEV-2 (High)**: Backdoors, malware, malicious access - Goal Mitigation SLA: 30 days
- **SEV-3/4 (Medium/Low)**: Suspicious emails, outages - Goal Mitigation SLA: 60 days or best effort


**Customer Reporting**:
- Email: security@montecarlodata.com
- Support helpdesk via customer agreements
- Tracked in Datadog and Freshdesk


**Post-Incident**:
- Post-mortems conducted for high and critical severity incidents
- Results tracked with action items assigned


### Vulnerability Disclosure Policy
**Source**: /docs/vulnerability-disclosure-policy âœ… PUBLIC DOC AVAILABLE


**Program Details**:
- Responsible disclosure program for security researchers
- 90-day confidentiality period for vulnerability resolution
- Initial confirmation within 72 hours of submission
- Security Researcher Wall of Fame for first reporters


**In Scope**:
- *.getmontecarlo.com
- *.dev.getmontecarlo.com
- *.montecarlodata.com


**Reporting**: security@montecarlodata.com


**Commitment**: No legal action for good-faith research following guidelines


### Human Resources & Personnel Security
**Source**: SOC 2 IS-02, IS-04, HR-02 (TO BE REPLACED WITH PUBLIC DOCS)


**Security Training**:
- Required within 30 days of hire
- Annual training thereafter
- Completion tracked and monitored


**Background Checks**:
- Conducted for personnel with access to customer data or production systems
- As permitted by local law
- Includes: criminal history, identity verification, employment history, education verification


**Confidentiality**:
- Confidentiality requirements in employee agreements
- Code of Conduct policy


### Change Management
**Source**: SOC 2 CM-01, CM-02, CM-03, CM-04 (TO BE REPLACED WITH PUBLIC DOCS)


**Process**:
- Formal authorization required for all changes
- Changes tested before production deployment
- Security analysis performed during change control
- Vulnerabilities tracked to resolution
- Independent approval required (branch protections)


**Patch Management**:
- Automated software update tools (CM-05)
- Operating systems run most recent security updates approved by management


### Data Retention & Disposal
**Source**: SOC 2 OM-04, C1.2 (TO BE REPLACED WITH PUBLIC DOCS)


**Retention**: Per customer agreement or configured retention policy


**Disposal Methods**:
- Secure deletion with cryptographic erasure for cloud-based data
- Full-disk encryption key destruction rendering data unrecoverable
- Overwriting backup media according to retention schedules


**Timeline**: Customer data disposed within 90 days of contract termination or customer request


**Confirmation**: Provided upon completion


### Risk Management
**Source**: SOC 2 RC-01, RC-02, RC-05 (TO BE REPLACED WITH PUBLIC DOCS)


**Annual Risk Assessment**:
- Includes fraud considerations
- Documented and tracked


**Third-Party Risk**:
- Annual third-party risk assessments for critical vendors
- Review of attestation reports (SOC 2, ISO, PCI)
- Due diligence reviews before vendor approval


**Insurance**:
- Cybersecurity insurance maintained


### Monitoring & Logging
**Source**: SOC 2 OM-01, OM-02, TV-02 (TO BE REPLACED WITH PUBLIC DOCS)


**Security Monitoring**:
- Continuous monitoring of system components
- Anomaly detection for malicious acts, natural disasters, errors
- Security event analysis to determine if incidents occurred
- 24/7 on-call security and engineering teams


**Event Types Monitored**:
- Failed object level access
- Daily intrusion attacks
- Critical IDS alerts
- Failed login attempts
- Network configuration changes


**Logging**:
- Centralized logging
- Security events tracked and monitored until resolved per defined SLAs


---


## AI-Specific Information


### Architecture (Only when AI questions asked)
**Sources**: /docs/ai-features-and-technical-info, /docs/llm-training-observability


**Key Points**:
- Monte Carlo uses pre-trained LLMs from Amazon Bedrock (US-east-1 region)
- Does NOT perform model training or fine-tuning
- LLMs hosted entirely within Monte Carlo's AWS environment
- No customer data used for current or future model training


**LLM Features**:
- Monitoring Agent: Monitor recommendations, SQL translation
- Troubleshooting Agent: Alert analysis and root cause identification
- Optional features that work with core product


### AI Security (Only when AI security questions asked)
**Source**: /docs/ai-security
- Security controls aligned with NIST and ISO 42001
- Data encrypted before AI service interaction
- Minimum necessary data sent, sensitive data anonymized where possible
- Strong customer data isolation (never co-mingled between customers)
- MFA required for AI system access
- Continuous monitoring of AI activity
- Annual security audits and penetration tests
- Subprocessors do NOT use AI metadata for their own training


---


## Common Response Templates


### SSO Support
"Yes. SSO via SAML 2.0 is supported. Additional features include SCIM provisioning and deprovisioning, Role-Based Access Control (RBAC), and least-privilege configurations."
**Source**: /docs/access-management


### Encryption Standards
"Monte Carlo uses AES-256 encryption for data at rest and TLS 1.2 or higher for data in transit. Encryption keys are managed through secure, audited key management systems with periodic rotation."
**Source**: /docs/data-protection-and-encryption


### Company Device Encryption
"Yes. All Monte Carlo-managed mobile devices are encrypted with full-disk encryption. Device management software enforces strong passwords, screen lock, and remote wipe capabilities."
**Source**: /docs/data-protection-and-encryption


### Cloud Provider
"Monte Carlo infrastructure is hosted exclusively on Amazon Web Services (AWS). The infrastructure follows AWS Well-Architected and CIS Benchmark guidelines and uses AWS Lambda for serverless compute with no persistent servers."
**Source**: /docs/infrastructure-security


### Third-Party Risk Management
"Monte Carlo works only with approved subprocessors who meet strict security and compliance requirements. All vendors undergo due diligence reviews and are bound by contractual data protection and confidentiality terms. No vendor receives account-level access outside specific engagements such as penetration testing."
**Source**: /docs/access-management


### Vulnerability Management
"Monte Carlo conducts ongoing vulnerability assessments through automated scans and third-party penetration tests. All findings are triaged by severity, tracked through defined SLAs, and re-tested following remediation."
**Source**: /docs/application-security


### SDLC Security
"Security is built into Monte Carlo's engineering workflows. Code undergoes static and dynamic analysis in CI/CD pipelines with automated dependency scanning. Every change requires peer review and approval. Testing includes OWASP Top 10 and CWE categories before deployment."
**Source**: /docs/application-security


---


**Last Updated**: December 3, 2024